---
title: "06b_prediction"
author: "Erin Dickie"
date: "5/2/2020"
output: html_document
---


# whole brain prediction

```{r message=FALSE, warning=FALSE}
library(here)
library(tidymodels)
library(vip)
library(tidyverse)
library(kernlab)
```

```{r setting paths}
# These functions are for reading timeseries files
source(here('code/R/settings_helpers.R'))

pheno <- read_pheno_file()%>%
  drop_na(DX) %>%
  filter(in_matched_sample)
YeoNet_colours <- define_Yeo7_colours()
Yeo7_2011_80verts <- read_Yeo72011_template()  

```
Load the connectivity data

```{r load-cached-results, eval=FALSE}
load(file.path(output_base, "all_clinicalplusqa_group", "Rdata_cache", "06_wholebrain_results_cache.Rdata"))

results_pheno <- all_corZ_results %>%
  inner_join(pheno, by = c("subject", "dataset")) %>%
  unnest(cols = c(the_corrs))
```

## merge if with the pheno data

```{r}
## edge to remove are those where the subcortical ROI's are too small
subcortical_guide <- get_subcortical_guide()
rois_too_small <- subcortical_guide %>% filter(size_is_ok == "no") %>% pull(combined_name)

```



```{r}
this_vertex_type <- "tvertex"
results_pheno_filterered <- results_pheno %>%
  
  ## filter for matche sample 
  filter(in_matched_sample) %>%
  
  ## filter for vertex type
  filter(vertex_type == this_vertex_type) %>%
  
  ## select the columns we want to include in our model 
  select(subject, dataset, DX, Age, Sex, fd_mean, Site, 
         from, to, weight) %>%

  ## remove the edges that are within a subcortical structure or too small
  filter(!(str_detect(to, "thalamus") & str_detect(from, "thalamus"))) %>%
  filter(!(str_detect(to, "striatum") & str_detect(from, "striatum"))) %>%
  filter(!(str_detect(to, "cerebellum") & str_detect(from, "cerebellum"))) %>%
  filter(!(to %in% rois_too_small)) %>%
  filter(!(from %in% rois_too_small)) %>%

  ## unite to and from columns into an FC edgename column
  unite(FC_edgename, from, to) 

## record the list of edges for later computations
FC_edgenames <- unique(results_pheno_filterered$FC_edgename)

## spread the edges across columns
brain_data <- results_pheno_filterered %>%
  group_by(subject, dataset, DX, Age, Sex, fd_mean, Site) %>%
  spread(FC_edgename, weight) %>%
  ungroup()
```

### Data prepared for `r this_vertex_type`

## the data splitting

```{r}
set.seed(123)
brain_split <- initial_split(brain_data, 
                            strata = Site)

brain_train <- training(brain_split)
brain_test  <- testing(brain_split)

set.seed(345)
folds <- vfold_cv(brain_train, v = 5)
folds
```


```{r}
brain_train %>%
  count(DX)
```
```{r}
brain_test %>%
  count(DX)
```


  
  
## set up a random forest engine with parsnip

```{r}
svm_recipe <- 
  recipe(DX ~ ., data = brain_data) %>%
  update_role(subject, dataset, new_role = "ID") %>%
  step_dummy(Site, Sex) %>%
  step_YeoJohnson(all_predictors()) %>%
  step_normalize(all_predictors()) #%>%
  #step_pca(one_of(FC_edgenames), threshold = 0.90) 
  
```

```{r eval = FALSE}
cores <- parallel::detectCores()
cores
```


```{r model}
svm_mod <-
  svm_poly(mode = "classification", cost = 1, degree = 3) %>%
  set_engine("kernlab")
```

```{r}
svm_workflow <- 
  workflow() %>% 
  add_model(svm_mod) %>% 
  add_recipe(svm_recipe)
```

```{r}
svm_parameters <- parameters(svm_workflow)
svm_parameters
```


```{r}
# runs the cross validated hyper parameter tuning
set.seed(345)
svm_res <- 
  svm_workflow %>% 
  last_fit(brain_split)
```



```{r}
## using autoplot to plot the results across the parameter grid
autoplot(svm_res)
```





### running the model one last time with the picked parameters from above

```{r}
# update model with hard coded best parameters from the above chunk
last_rf_mod <- 
  rand_forest(mtry = 94, min_n = 38, trees = 1000) %>% 
  set_engine("ranger", num.threads = 2, importance = "impurity") %>% 
  set_mode("classification")
```

```{r}
# the last workflow
last_rf_workflow <- 
  rf_workflow %>% 
  update_model(last_rf_mod)

# the last fit is apparently another way of spliting doing the final fit
set.seed(345)
last_rf_fit <- 
  last_rf_workflow %>% 
  last_fit(data1_split) ## splits

last_rf_fit
```


```{r}
## print accuracy and roc
svm_res %>% 
  collect_metrics()
```
```{r}
### plotting the roc curve
svm_res %>% 
  collect_predictions() %>% 
  roc_curve(DX, .pred_SSD) %>% 
  autoplot()
```


```{r fig.height=10, fig.width=6}
## plotting the very important predictors
last_rf_fit %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(num_features = 100)
```


### ploting the ROC curv 





(this one is colour coded across two fits)

```{r}
bind_rows(rf_auc, lr_auc) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)
```

